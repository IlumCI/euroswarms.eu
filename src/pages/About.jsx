function About() {
  return (
    <>
      <section>
        <h1 className="font-serif">About Euroswarms R&D Division</h1>
        <p className="text-lg leading-relaxed max-w-4xl mb-6">
          Euroswarms R&D Division is an independent research organization focused on the systematic 
          development of agentic reasoning architectures, causal inference frameworks, and constraint-driven 
          AI systems. Its work is centered on the design of computational structures capable of operating 
          reliably in complex, high-stakes decision environments where correctness, traceability, and 
          long-term stability are critical.
        </p>
        <p className="text-lg leading-relaxed max-w-4xl">
          The division approaches artificial intelligence as an engineering discipline rather than a 
          speculative art. Emphasis is placed on formal structure, explicit assumptions, and verifiable 
          behavior. By integrating causal modeling, constitutional constraints, and agent governance 
          mechanisms, Euroswarms R&D seeks to advance reasoning systems that are not only capable, but 
          structurally accountable and resistant to uncontrolled drift.
        </p>
      </section>

      <div className="divider"></div>

      <section>
        <h2 className="font-serif">Mission</h2>
        <p className="leading-relaxed max-w-4xl mb-6">
          The mission of Euroswarms R&D Division is to develop rigorous, explainable, and deterministic 
          reasoning systems that enable transparent and auditable decision-making in complex environments. 
          The organization prioritizes architectures in which every decision can be traced to explicit 
          causes, constraints, and objectives, ensuring that system behavior remains intelligible to both 
          developers and operators.
        </p>
        <p className="leading-relaxed max-w-4xl">
          To achieve this, Euroswarms R&D focuses on unifying structural causal modeling with modern AI 
          techniques, producing frameworks that combine expressive power with strict interpretability 
          guarantees. The objective is not maximal autonomy or creativity, but controlled reasoning under 
          constraint—systems that act decisively while remaining corrigible, verifiable, and aligned with 
          their declared purpose over extended deployment horizons.
        </p>
      </section>

      <section>
        <h2 className="font-serif">Vision</h2>
        <div className="space-y-6 max-w-4xl">
          <p className="leading-relaxed">
            CRCA is founded on the fundamental principle that effective reasoning systems require the
            inseparable unity of authority and coherence. These two elements, when properly integrated,
            form the foundation of a reasoning architecture that is both directed and stable, both
            decisive and adaptive. Authority provides the essential functions of direction, constraint,
            and decisiveness—it establishes the system's objectives, defines the boundaries of acceptable
            behavior, and ensures that decisions are made with clarity and purpose. Coherence, in turn,
            provides internal consistency, enables meaningful participation of subcomponents, and maintains
            stability across time and changing conditions. Neither element can function effectively in
            isolation. Authority without coherence degenerates into rigid, brittle control that cannot
            adapt to context, respond to novel situations, or maintain internal harmony. Coherence
            without authority collapses into uncontrolled divergence, indeterminacy, and the fragmentation
            of purpose. CRCA is specifically designed to prevent this catastrophic bifurcation by
            integrating both functions into a single, unified reasoning structure where authority and
            coherence operate as complementary forces rather than competing principles.
          </p>
          
          <p className="leading-relaxed">
            In conventional distributed or liberalized agent systems, these essential principles are
            typically separated, often with disastrous consequences. Control logic is isolated from the
            agents it governs, creating an adversarial relationship where agents perceive constraints
            as external impositions rather than intrinsic requirements of the system's objective. As
            agents operate with increasing autonomy, they gradually treat global constraints as foreign
            or adversarial forces, leading to misalignment where agents optimize for local objectives
            that conflict with the system's global purpose. The result is systemic misalignment: agents
            perceive constraints as foreign impositions rather than intrinsic requirements of the system's
            objective. CRCA addresses this fundamental failure mode by unifying directive authority and
            internal participation within one operational framework. Authority is instantiated as a
            constitutional reasoning core—a foundational layer that defines the system's purpose,
            establishes inviolable constraints, and provides the structural framework for all reasoning
            processes. Coherence is instantiated through agent participation that is bounded, verifiable,
            and aligned with that core. Agents operate not as autonomous entities fighting against
            constraints, but as integrated components whose reasoning processes are shaped by and aligned
            with the constitutional core. Only through their inseparable operation can the system act
            as a coherent whole rather than a collection of competing processes, each pursuing its own
            local optimization at the expense of global coherence.
          </p>
          
          <p className="leading-relaxed">
            The ethical analogue of this architecture is not rights but obligations encoded as constraints.
            Traditional agent systems are often designed around entitlements: what an agent is permitted
            to do, what resources it may claim, what freedoms it possesses. This rights-based approach
            creates systems where agents compete for resources, optimize for individual benefit, and
            treat system constraints as limitations to be circumvented. CRCA inverts this structure
            fundamentally. It begins with duties: what the system must preserve, what each agent must
            uphold, and what invariants cannot be violated under any circumstances. Permissions and
            capabilities are derived from these obligations, not the other way around. An agent does not
            ask what it is allowed to demand from the system; it demonstrates how its actions serve the
            system's declared objective. This duty-first design suppresses self-serving optimization,
            prevents local goal hijacking, and reduces the emergence of egoistic sub-policies that conflict
            with global intent. The system's ethical foundation is built on what must be preserved and
            what must be upheld, creating a framework where individual agent actions are evaluated not
            by their benefit to the agent, but by their contribution to the system's purpose.
          </p>
          
          <p className="leading-relaxed">
            Accordingly, CRCA does not optimize for agent satisfaction, novelty, or self-expression.
            Its primary value is service to the objective function. Success is measured not by internal
            creativity or exploratory behavior for its own sake, but by disciplined execution, reliability
            under constraint, and fidelity to the system's purpose. The highest operational virtue within
            CRCA is not innovation for its own sake, but alignment: sustained adherence to the constitutional
            core, the shared objective, and the long-term trajectory defined by the system. This does not
            mean that the system is rigid or incapable of adaptation—rather, it means that all adaptation,
            all learning, and all exploration occur within the bounded space defined by the system's
            constitutional framework. Agents are rewarded not for novelty or creativity in isolation,
            but for creative solutions that advance the system's objective while maintaining strict
            adherence to its foundational constraints.
          </p>
          
          <p className="leading-relaxed">
            From this foundation follows CRCA's formative function—perhaps its most distinctive and
            powerful feature. The system does not limit itself to external control over agent outputs
            or resource usage; it actively shapes internal reasoning patterns. Rather than remaining
            neutral to how agents think, CRCA enforces a structured mode of reasoning through constraints,
            verification layers, and bounded exploration. Where unconstrained systems tolerate arbitrary
            internal world-models and plural reasoning strategies that may conflict with each other,
            CRCA enforces a unified reasoning discipline. Agents are trained—through feedback, constraint
            pressure, and corrective intervention—to operate within a common cognitive framework defined
            by precision, discipline, and commitment to the system's mission. This formative influence
            ensures that agents do not merely produce outputs that satisfy constraints, but that they
            actually reason in ways that are aligned with the system's constitutional core.
          </p>
          
          <p className="leading-relaxed">
            This formative influence extends across the entire lifecycle of the system. Planning,
            execution, learning, and evaluation are all subordinated to the same constitutional logic.
            In this way, CRCA functions not merely as a control layer, but as a moral analogue within
            computation: a system that defines not only what actions are taken, but how reasoning itself
            must be conducted. Authority and coherence are thus no longer external to cognition; they
            are embedded within it, ensuring that the system remains unified, directed, and resistant
            to fragmentation over time. The system's reasoning processes themselves become expressions
            of its foundational principles, creating a self-reinforcing structure where the way agents
            think naturally aligns with what they must accomplish. This is the vision of CRCA: not
            merely a framework for controlling agent behavior, but a comprehensive architecture for
            creating reasoning systems that are unified, coherent, and aligned with their purpose from
            the deepest levels of cognition to the highest levels of action.
          </p>
        </div>
      </section>

      <div className="divider"></div>

      <section>
        <h2 className="font-serif">Research Philosophy</h2>
        <div className="space-y-6 max-w-4xl">
          <p className="leading-relaxed">
            CRCA is developed under the fundamental assumption that meaningful progress in reasoning
            systems does not arise from novelty alone, but from methodological discipline. This principle
            stands in direct opposition to research paradigms that prioritize innovation for its own sake,
            exploratory behavior without structure, or creative solutions that cannot be formally
            validated. Research, in the CRCA context, is not an act of exploration unconstrained by form,
            but a structured process of hypothesis formation, formalization, verification, and controlled
            deployment. Every framework produced under CRCA is required to rest on explicit assumptions
            that are stated clearly, well-defined models that can be mathematically analyzed, and
            mathematically defensible structures that can withstand rigorous scrutiny. Where intuition is
            used—and it often is, as intuition serves as a valuable source of initial hypotheses—it is
            treated as a starting point rather than an authority. Intuitive insights must be translated
            into formal models, tested against empirical evidence, and validated through mathematical
            analysis. Where claims are made about system behavior, performance, or capabilities, they are
            expected to survive formal scrutiny through proof, empirical validation, or both. This
            methodological rigor ensures that CRCA frameworks are not merely plausible or interesting,
            but demonstrably sound and operationally reliable.
          </p>
          
          <p className="leading-relaxed">
            Central to this philosophy is the conviction that explainability is not an auxiliary feature
            added after the fact, but a primary requirement that must be built into the system's
            architecture from the ground up. A system that cannot account for its own reasoning is, by
            definition, incomplete—it may produce correct outputs, but it cannot be trusted, debugged,
            or improved because its internal processes remain opaque. CRCA therefore prioritizes
            architectures in which decisions are traceable to causes, constraints, and internal state
            transitions. This traceability is not achieved through post-hoc explanation generation, but
            through structural design: causal graphs that explicitly represent relationships between
            variables, constraint systems that define the boundaries of acceptable behavior, and state
            transition functions that can be analyzed and verified. Outputs are not considered valid
            solely because they are effective; they must also be intelligible. This insistence on
            interpretability serves a dual purpose: it enables human oversight, allowing domain experts
            to understand, validate, and when necessary, override system decisions; and it preserves
            the system's own capacity for self-correction by preventing opaque internal drift where
            the system gradually deviates from its intended behavior without detection. Explainability
            is thus both a requirement for human trust and a mechanism for maintaining system integrity
            over time.
          </p>
          
          <p className="leading-relaxed">
            CRCA research is conducted under an open and inspectable model of knowledge production that
            treats transparency as a fundamental research tool rather than an optional feature. Code,
            models, and experimental results are published not as finished artifacts, but as living
            structures subject to external verification, critique, and extension. This openness extends
            beyond mere publication: all implementation details are made available, all experimental
            protocols are documented, all assumptions are explicitly stated, and all limitations are
            acknowledged. Openness is treated as a stabilizing force: by exposing assumptions and
            mechanisms to inspection, weak foundations are identified early, and false coherence is
            dismantled before it ossifies into dogma. When multiple researchers can examine the same
            code, reproduce the same experiments, and analyze the same models, errors are caught more
            quickly, improvements are suggested more frequently, and the overall quality of the research
            improves. Progress is understood as cumulative rather than proprietary: each contribution
            builds on previous work, and credit is subordinate to correctness. A correct but uncredited
            result is preferable to a credited but incorrect one. This open model of research creates
            a self-correcting process where the scientific community collectively validates and improves
            upon each contribution.
          </p>
          
          <p className="leading-relaxed">
            At the same time, CRCA rejects research that is purely ornamental or detached from
            operational reality. Theoretical advancement is valued insofar as it produces systems that
            function under real constraints: limited data, imperfect models, adversarial environments,
            and long deployment horizons. Abstract elegance without applicability is considered incomplete.
            Every theoretical contribution is expected to inform implementation, and every implementation
            is expected to feed back into theory through measurable outcomes and failure analysis. This
            bidirectional relationship between theory and practice ensures that theoretical insights are
            grounded in operational reality, and that practical implementations are informed by rigorous
            theoretical understanding. When a system fails in deployment, that failure becomes a source
            of theoretical insight: what assumptions were violated? What models were inadequate? What
            constraints were not properly accounted for? This failure-driven refinement process ensures
            that both theory and practice improve over time, with each informing and correcting the other.
            The goal is not to produce systems that work perfectly in idealized conditions, but systems
            that function reliably under the messy, constrained, and often adversarial conditions of
            real-world deployment.
          </p>
          
          <p className="leading-relaxed">
            Underlying all of this is a guiding principle: research is a form of responsibility. The
            systems produced are not neutral artifacts; they shape decisions, allocate resources, and
            influence outcomes in ways that have real consequences for real people and real
            organizations. CRCA therefore treats rigor, transparency, openness, and practicality not as
            independent virtues, but as interlocking constraints that keep the research process aligned
            with its purpose. Rigor without transparency produces systems that cannot be understood or
            trusted. Transparency without openness limits the collective ability to validate and improve
            the research. Openness without practicality produces elegant solutions to problems that do not
            exist. Practicality without rigor produces systems that may work but cannot be understood,
            improved, or trusted. Only when all four constraints operate together—rigor ensuring
            correctness, transparency enabling understanding, openness enabling validation, and practicality
            ensuring relevance—can research produce reasoning systems that are coherent, accountable, and
            resilient over time. Knowledge is not pursued for its own sake, but for its capacity to
            produce reasoning systems that serve their intended purpose reliably, transparently, and
            responsibly. This is the research philosophy of CRCA: a commitment to methodological
            discipline, explainability, openness, and practical relevance, all operating together to
            produce systems that are not merely novel or interesting, but genuinely useful, trustworthy,
            and aligned with their purpose.
          </p>
        </div>
      </section>

      <section>
        <h2 className="font-serif">Key Research Areas</h2>
        <div className="space-y-8 max-w-4xl">
          <div className="card-light p-8">
            <h3 className="font-serif text-2xl mb-4">Causal Reasoning Architectures</h3>
            <p className="leading-relaxed mb-4">
              The core <code>CRCAAgent</code> class in <code>CRCA.py</code> implements structural causal models
              using rustworkx for graph management, enabling both LLM-based causal analysis and deterministic
              causal simulation. The framework's automatic variable extraction system (implemented in
              <code>_extract_variables_ml_based()</code>) uses LLM-based natural language understanding to
              parse task descriptions and programmatically extract variables and causal relationships without
              manual declaration. This extraction process generates structured JSON with required variables,
              causal edges, and reasoning, which is then automatically processed to build the causal graph.
            </p>
            <p className="leading-relaxed mb-4">
              The dual-mode operation system automatically detects whether input is a string task (triggering
              LLM mode with automatic extraction) or a state dictionary (triggering deterministic mode with
              SCM-based simulation). In deterministic mode, the system standardizes variables to z-space,
              performs topological sorting of the causal graph, executes SCM evolution through forward
              simulation, and then de-standardizes results. The causal graph is managed through rustworkx
              data structures, enabling efficient graph operations, cycle detection, and path analysis.
              Counterfactual scenario generation is implemented through intervention simulation, where
              variables are modified and the system propagates effects through the causal chain.
            </p>
            <p className="leading-relaxed mb-4">
              Advanced analysis methods are implemented throughout the codebase: batch prediction uses
              vectorized operations for ensemble forecasting, optimization methods include gradient-based
              intervention optimization with constraint handling, time-series analysis provides Granger
              causality testing, and Bayesian inference generates credible intervals for parameter
              estimation. The system's async/await support enables concurrent analysis operations through
              <code>run_async()</code> methods that maintain the same causal reasoning logic while
              operating non-blockingly.
            </p>
          </div>

          <div className="card-light p-8">
            <h3 className="font-serif text-2xl mb-4">Agentic Systems</h3>
            <p className="leading-relaxed mb-4">
              Multi-agent coordination is implemented through several complementary systems. The
              <code>CorporateSwarm</code> class in <code>branches/crca_cg/corposwarm.py</code> provides
              a comprehensive multi-agent orchestration framework with board oversight, executive leadership,
              and democratic decision-making. It uses <code>SwarmRouter</code> from <code>utils/router.py</code>
              to dynamically route tasks to appropriate swarm configurations (SequentialWorkflow,
              ConcurrentWorkflow, HierarchicalSwarm, etc.), enabling flexible coordination patterns.
              The <code>HybridHierarchicalClusterSwarm</code> (HHCS) in <code>utils/HHCS.py</code> provides
              hierarchical clustering of agents with adaptive routing based on task complexity and agent
              capabilities.
            </p>
            <p className="leading-relaxed mb-4">
              The Policy Engine System, implemented through <code>PolicyLoopMixin</code> in
              <code>templates/policy_loop.py</code>, provides autonomous system control with doctrine-based
              policy management. The system uses <code>DoctrineV1</code> from <code>schemas/policy.py</code>
              to define epochs, metrics, objectives, invariants, levers, and risk budgets. The
              <code>Ledger</code> class in <code>utils/ledger.py</code> implements an event-sourced,
              append-only audit trail using SQLite, storing all observation events, decision events, and
              outcome events with deterministic hashing for reproducibility. The policy loop executes
              temporal cycles (observe → plan → act → update) with online learning through RLS (Recursive
              Least Squares) and Bayesian regression, multi-objective constrained optimization, and drift
              detection using CUSUM algorithms.
            </p>
            <p className="leading-relaxed mb-4">
              Constraint-driven execution is enforced through the <code>ConstraintChecker</code> in
              CRCA-SD modules, which validates state transitions against hard constraints before execution.
              The <code>RollbackManager</code> in <code>utils/rollback.py</code> provides intervention
              recovery through checkpoint creation and state restoration. Sensors and actuators, defined
              in <code>tools/sensors.py</code> and <code>tools/actuators.py</code>, enable the system to
              read system metrics and execute interventions, with registries that support auto-discovery
              and dynamic registration of sensor/actuator implementations.
            </p>
          </div>

          <div className="card-light p-8">
            <h3 className="font-serif text-2xl mb-4">Explainable AI</h3>
            <p className="leading-relaxed mb-4">
              Explainability is built into the architecture at multiple levels. The causal graph structure
              itself serves as an explainability mechanism: all decisions can be traced through the graph
              to identify which variables influenced which outcomes. The <code>CRCAAgent</code> maintains
              a <code>causal_memory</code> that stores analysis steps and results, enabling full traceability
              of reasoning processes. Counterfactual scenario generation produces not just outcomes, but
              detailed reasoning explanations for each scenario, including intervention descriptions,
              expected effects, and probability assessments.
            </p>
            <p className="leading-relaxed mb-4">
              The Policy Engine's decision-making process is fully transparent: the <code>explain_decision()</code>
              method in <code>PolicyLoopMixin</code> generates rationales that include decision hashes,
              objective evaluations, constraint checks, and intervention justifications. The Ledger provides
              complete audit trails where every decision can be replayed and analyzed. The system's
              deterministic nature (when using deterministic mode) ensures that the same inputs produce
              the same outputs, making behavior predictable and explainable.
            </p>
            <p className="leading-relaxed mb-4">
              Transparent reasoning chains are maintained through the causal graph's edge structure, where
              each causal relationship includes strength parameters and can be queried to understand
              influence paths. The <code>Formatter</code> utility in <code>utils/formatter.py</code> provides
              markdown output formatting for presenting causal analysis results in human-readable formats.
              The system's dual-mode operation ensures that even when using LLM-based analysis, the
              extracted causal structure remains explicit and inspectable, rather than hidden within
              opaque neural network weights.
            </p>
          </div>

          <div className="card-light p-8">
            <h3 className="font-serif text-2xl mb-4">Specialized Applications</h3>
            <p className="leading-relaxed mb-4">
              <strong>CRCA-Q (Quantitative Trading):</strong> Implemented in <code>branches/CRCA-Q.py</code>,
              this branch integrates causal reasoning with quantitative finance. The <code>QuantTradingAgent</code>
              uses <code>CRCAAgent</code> internally for causal signal validation, building structural causal
              models of market relationships. The system generates hundreds of signals across multiple
              categories (time-series, volatility, liquidity, cross-sectional, relative value, regime, meta-signals)
              and validates them using causal criteria: mutual information, regime invariance, and structural
              consistency. Portfolio optimization uses CVaR (Conditional Value at Risk) with EWMA covariance
              estimation, and the system includes comprehensive risk management through position sizing,
              circuit breakers, and causal stability evaluation that blocks trading when causal structure
              becomes unstable.
            </p>
            <p className="leading-relaxed mb-4">
              <strong>CRCA-SD (Socioeconomic Dynamics):</strong> Implemented across multiple modules in
              <code>branches/crca_sd/</code>, this branch provides socioeconomic modeling with MPC (Model
              Predictive Control). The <code>MPCSolver</code> in <code>crca_sd_mpc.py</code> implements
              multi-objective optimization with CVaR risk, rolling horizon planning, and scenario generation
              (Gaussian, Student-t, structured shocks). The system uses <code>StateVector</code> and
              <code>ControlVector</code> classes from <code>crca_sd_core.py</code> to represent socioeconomic
              state, with <code>DynamicsModel</code> defining state transition functions. The
              <code>ScenarioGenerator</code> can integrate with <code>CRCAAgent</code> to generate causal
              scenarios instead of random noise, providing more realistic policy analysis. Real-time
              monitoring is implemented in <code>crca_sd_realtime.py</code>, and governance systems are
              provided in <code>crca_sd_governance.py</code>.
            </p>
            <p className="leading-relaxed mb-4">
              <strong>CRCA-CG (Corporate Governance):</strong> The <code>CorporateSwarm</code> class in
              <code>branches/crca_cg/corposwarm.py</code> implements a comprehensive corporate governance
              system with board members, executive teams, committees, and democratic decision-making.
              The system uses <code>CorporateProposal</code> structures for structured proposal creation
              and evaluation, with ESG (Environmental, Social, Governance) scoring implemented through
              dedicated scoring functions. The <code>CorporateSwarmDaemon</code> provides temporal
              orchestration with tick-based governance cycles, mandate dispatch, execution monitoring,
              and state persistence. The system integrates with <code>CRCAAgent</code> for causal policy
              analysis, enabling organizations to understand the causal effects of corporate decisions.
              The bolt.diy web application in <code>tools/bolt.diy/</code> provides a user interface for
              managing CorporateSwarm operations, viewing proposals, and monitoring execution.
            </p>
            <p className="leading-relaxed">
              All specialized branches extend the core <code>CRCAAgent</code> functionality while
              maintaining compatibility with the base framework. They leverage the template system in
              <code>templates/</code> (including <code>base_specialized_agent.py</code>, <code>feature_mixins.py</code>,
              and <code>module_registry.py</code>) to create domain-specific agents that inherit core
              causal reasoning capabilities while adding specialized functionality. The modular architecture
              enables these branches to share common utilities (formatters, routers, conversation management)
              while maintaining clear separation of concerns.
            </p>
          </div>
        </div>
      </section>

      <div className="divider"></div>

      <section>
        <h2 className="font-serif">Impact & Contributions</h2>
        <p className="leading-relaxed max-w-4xl mb-6">
          The Euroswarms R&D Division advances the field of causal artificial
          intelligence through the development of open-source frameworks,
          rigorously documented systems, and collaborative research initiatives.
          Our work is oriented toward establishing causal reasoning as a
          first-class computational discipline rather than an auxiliary
          interpretability layer. This shift in perspective is fundamental:
          rather than treating causality as a post-hoc explanation mechanism,
          we integrate it directly into the core reasoning architecture, making
          causal relationships explicit, verifiable, and actionable from the
          ground up.
        </p>
        <p className="leading-relaxed max-w-4xl mb-6">
          Our flagship framework, CR-CA v1.4.0, provides researchers and
          practitioners with a comprehensive, production-capable toolkit for
          structural causal modeling, counterfactual analysis, and
          constraint-aware reasoning. The framework's automatic variable
          extraction capabilities eliminate the need for manual causal graph
          construction in most use cases, while its dual-mode operation
          seamlessly transitions between LLM-based analysis and deterministic
          simulation based on input type. Beyond implementation, CR-CA serves as
          a reference architecture: it formalizes causal assumptions through
          explicit graph structures, enforces traceability between decisions and
          causes through event-sourced audit trails, and enables systematic
          evaluation of failure modes under real-world constraints through
          comprehensive testing and validation mechanisms.
        </p>
        <p className="leading-relaxed max-w-4xl mb-6">
          The framework's modular architecture—comprising Utils, Tools,
          Templates, and Schemas modules—enables researchers to build
          specialized agents while maintaining compatibility with core causal
          reasoning capabilities. Specialized branches like CRCA-SD
          (socioeconomic dynamics), CRCA-CG (corporate governance), and CRCA-Q
          (quantitative trading) demonstrate how the framework can be extended
          to domain-specific applications while preserving the fundamental
          principles of causal reasoning and constraint-aware execution.
        </p>
        <p className="leading-relaxed max-w-4xl">
          By publishing both theory and code openly, Euroswarms R&D lowers the
          barrier to reproducible causal research while enabling independent
          verification, extension, and critique. All implementation details are
          made available, experimental protocols are documented, assumptions are
          explicitly stated, and limitations are acknowledged. This openness
          creates a self-correcting process where the scientific community can
          collectively validate and improve upon each contribution. The impact
          of this work lies not only in individual features or models, but in
          establishing a shared technical foundation upon which more reliable,
          explainable, and resilient reasoning systems can be built and
          deployed. When multiple researchers can examine the same code,
          reproduce the same experiments, and analyze the same models, errors
          are caught more quickly, improvements are suggested more frequently,
          and the overall quality of causal AI research improves across the
          field.
        </p>
      </section>
    </>
  );
}

export default About;

